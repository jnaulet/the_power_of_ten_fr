# La puissance de 10 - Des Règles pour Développer du Code Critique Sûr

*Gerard J. Holzmann, traduction par J.Naulet*

*NASA/JPL Laboratory for Reliable Software*

*PAsadena, CA 91109*

La plupart des projets sérieux de développement logiciel utilisent des lignes directrices. Celles-ci ont pour but de définir quelles sont les règles de base pour le logiciel à écrire : comment il doit être structuré & quelles caractéristiques du langage doivent ou ne doivent pas être utilisées. Etonnament, il y a peu de consensus sur ce qu'est un bon standard de codage. Parmi le grand nombre qui ont été écrits, on discerne peu de motifs récurrents, à l'exception du fait que chaque docuement tend à être plus long que le précedent. Le résultat étant que la plupart des documents existants contiennent bien plus d'une centaine de règles, à la justification parfois discutable. Certaines règles, notamment celles qui tentent de définir l'usage des espaces dans les programmes, peuvent avoir été introduites par simple préférence personnelle; d'autres ont pour but d'éviter certains types d'erreurs improbables & très spécifiques, fruit d'efforts précédents au sein d'une même organisation. Sans surprise, les lignes directrices existantes tendent à n'avoir que peu d'effet sur ce que font les developpeurs quand ils écrivent réellement le code. L'aspect le plus élimnatoire de beaucoup de ces lignes directrices est qu'elle autorisent rarement une vérification complète & automatique de la conformité. La vérification par des outils tiers est importante, étant donné qu'il est souvent impossible de faire une revue de code manuelle des milliers de lignes de code présentes dans les plus grosses applications.


Le bénéfice des lignes directrices existantes est par conséquent souvent mineur, même pour les applications critiques. Un ensemble vérifiable de règles de codage bien choisies peut, néanmoins, rendre les éléments logiciels plus analysables en profondeur, pour des propriétés qui vont au delà de la conformité avec ces mêmes règles. Pour être fficace, cependant, cet ensemble de règles doit être concis, et doit être assez clair pour pouvoir être compris & retenu. Les règles devront être suffisamment précises pour pouvoir être vérifiée mécaniquement. Pour mettre une limite haute quant au nombre de règles pour des lignes directrices efficaces, j'arguerais que nous pouvons obtenir un bénéfice significatif en réduisant le nombre à pas plus de 10. Un ensemble aussi réduit, bien sûr, ne peut tout englober, mais il peut nous donner un ancrage pour atteindre des effets mesurables sur la fiabilitié & la vérifiabilite (?) du logiciel. Pour permettre une vérification forte, les règles sont quelque peu strictes - certains diraient même Draconniennes. Le compromis, ceci dit, doit être clair. Quand c'est vraiment important, en particulier lors du développement de code de sécurité critique, il peut être utile d'aller plus loin & de fixer des limites plus strictes que ce qui est simplement souhaitable. En échange, nous devrions être capables de démontrer de façon plus convaincante que le logiciel critique fonctionne comme prévu.

## Dix Règles pour un Code Critique Sûr
Le choix du langage pour un code critique sécurisé est en soi une considération clé, mais nous n'en débattrons pas beaucoup ici. Dans de nombreuses organisations, JPL inclus, le code critique est écrit en C. De par son long historique, il existe un grande bibliothèque d'outils pour ce langage, incluant de puissants analyseurs de code source, des extracteurs de modèles logiques, des outils de mesure, débogueurs, outils de tests, & un vaste choix de compilateurs stables & au point. Pour cette raison, le C est aussi le sujet principal de le plupart des lignes directrices  qui ont été développées. Pour des raisons raisonnablement pragmatiques, donc, nos règles de codage s'appliquent au C & tentent d'optimiser notre capacité à vérifier plus en profondeur la fiabilité des applications critiques écrites en C.

Les règles suivantes peuvent fournir un bénéfice, en particulier si leur faible nombre signifie que les developpeurs vont reéllement les appliquer. Chaque règle s'accompagne d'un rapide résumé qui explique son inclusion.

1. ***Règle***: Réduire le code à des constructions simples de flux de contrôle - N'utilisez pas d'instructions *goto*, *setjmp* ou *longjmp* ni de *récursion* direct ou indirecte.

***Justification***: Un flux de contrôle plus simple se traduit par de plus grandes capacités de vérification & souvent une amélioration de la clarté du code. L'interdiction de la récursion est peut-être le plus grosse surprise ici. Sans récursion, ceci dit, nous avons la garantie d'un arbre d'appels des fonctions acyclique, qui peut être exploîté par des analyseurs de code, et qui peut directement aider à démontrer que toutes les exécutions qui doivent être couvertes le sont. (Notez que cette règle ne requiert pas que toutes les fonctions n'aient qu'un unique point de retour - bien que cela simplifie souvent le flux de contrôle. Il y a suffisamment de cas, en fait, où un retour d'erreur anticipé est la solution la plus simple)

2. ***Règle***: Toutes les boucles doivent avoir une limite haute fixe. Il doit être ridiculement facile pour un outil d'analyse de prouver statiquement qu'une limite d'itérations prédéfinie ne peut être dépassée. Si la limitation ne peut être prouvée de façon statique, la règle est considérée comme violée.

***Justification***: L'absence de récursion & la présence de boucles limitées empêche la jardinage en mémoire. Cette règle, bien sûr, ne s'applique pas aux itérations infinies par essence (ex: dans un scheduler de process). Dans ces cas particuliers, la règle inverse est appliquée: il doit être possible de prouver statiquement que l'itération *ne peut* se terminer.
Une fois d'appliquer cette règle est d'ajouter explicitement une limite haute à toutes les boucles ayant un nombre variable d'itérations (ex: un code qui parcourerait une liste chaînée). Quand la limite haute est dépassée une assertion d'échec est lancée & la fonction contenant l'itération fautive retourne une erreur. (Voir règle 5 sur l'utilisation des assertions).


3. ***Règle***: Ne pas utiliser d'allocation mémoire dynamique après l'initialisation.

***Justification***: Cette règle est courante pour le code critique de sécurité & apparaît dans la plupart des lignes directrices. La raison est simple: les allocateurs mémoire, tels que *malloc* & les ramasse-miettes ont souvent un comprtement non prévisible qui peut impacter la performance de façon significative. Une classe notable d'erreurs de codage émerge d'une mauvaise prise en charge de l'allocation mémoire & des routines de libération: oulbier de libérer la mémoire ou conitnuer à à utiliser la mémoire après qu'elle ait été libérée, tenter d'allouer plus de mémoire qu'il n'y en a de physiquement disponible, dépasser les limites de la mémoire allouée, etc. Forcer toutes les applications à vivre dans une zone mémoire fixe, pré-allouée peut éliminer beaucoup de ces problèmes & rendre la vérification de l'utilisation mémoire plus facile. Notez que la seule façon de demander dynamiquement de la mémoire en l'absence d'allocation mémoire en provenance du tas *(heap)* est d'utiliser la mémoire de la pile. En l'absence de récursion (Règle 1), une limite haute quant à l'utilisation de la pile mémoire peut être déduite statiquement, rendant possible de prouver qu'une application va toujours vivre à l'intérieur de sa zone pré-allouée.

4. ***Règle***: Auncune fonction ne doit être plus longue que ce qui peut être imprimé sur une feuille de papier dans un format standard de référence avec une ligne par définition & une ligne par déclaration. Typiquement, cela signifie pas plus de 60 lignes de code par fonction.

***Justification***: Chaque fonction doit être une unité logique dans le code qui est compréhensible & vérifiable en tant qu'unité. Il est beaucoup plus difficile de comprendre une unité logique qui s'étend sur plusieurs écrans sur un affichage d'ordinateur ou sur de multiples pages une fois imprimée. Les fonctions excessivement longues sont souvent un marqueur d'un code très mal structuré.

5. ***Règle***: La *densité d'assertions* du code doit être en moyenne d'au moins 2 assertions par fonction. Les assertions sont utilisées pour se protéger de conditions anormales qui ne devraient jamais se produire lors d'exécutions en conditions réelles. Les assertions doivent toujours être sans aucun effet de bord & doivent être définies en tant que tests Booléens. Quand une asseertion échoue, une action de sauvetage doit être entreprise, ex, en retournant une erreur à l'appelant de la fonction qui exécute l'assertion échouée. Toute assertion pour laquelle un analyseur statique peut prouver qu'elle ne peut jamais échouer ou jamais réussir viuole cette règle. (Il n'est pas possible de satisfaire cette exigence en ajoutant d'inutiles appels à *"assert(true)"*.)

***Justification***: Les statistiques pour les efforts de codage industriel indiquent que les tests unitaires trouvent souvent au moins une erreur pour 10 à 100 lignes de code écrites. Les chances d'intercepter ces erreurs augmente avec la densité des assertions. L'utilisation des assertions est aussi souvent recommandée en tant qu'élément d'une stratégie de codage fortement défensive. Les assertions peuvent être tuilisées pour vérifier pré- & post- conditions de fonctions, valeurs de paramètres, valeurs de retour des fonctions, & constantes de boucles. Comme les assertions sont sans effet de bord, elles peuvent être désactivées sélectivement pour les tests de performances critiques.
Un usage typique d'assertion serait le suivant:

    if (!c_assert(p >= 0) == true) {
      return ERROR;
    }

avec l'assertion décrite ainsi :

    #define c_assert(e) ((e) ? (true) : \
     tst_debugging(”%s,%d: assertion ’%s’ failed\n”, \
     __FILE__, __LINE__, #e), false)

Dans cette définition, __FILE__ & __LINE__ sont prédéfinies par le préprocesseur de macros & correspondent au nom du fichier & le numéro de ligne de l'assertion échouée. La syntax #e transforme la condiution d'assertion e en chaîne de caractères qui est affichée en tant qu'élement du message d'erreur. Dans un code destiné à un processeur embarqué if n'y a bien sûr pas lieu d'afficher le message d'erreur lui-même - Dans ce cas, l'appel à tst_debugging est trasnformé en no-op, & l'assertion se tranforme en pur test Booléen qui active la gestion d'erreur à partir du comportement anormal.

6. ***Règle***: Les objets & variables doivent être déclarés au niveau de portée le plus faible.

***Justification***: Cette règle applique le principe basique de protection des données. Clariement si un objet n'est pas à portée, sa valeur ne peut être référencée ou corrompue. De la même façon, si une valeur erronnée d'une objet doit être diagnostiquée, moins il y a de déclarations où la valeur a pu être assignée; plus il sera facile de diagnotisquer le problème. Cette règle décourage la réutilisation de variables dans des buts différents & incompatibles, qui peut compliquer la détection d'erreur.


7. ***Règle***: La valeur de retour des fonctions non-void doit être vérifiée par chaque fonction appelante, & la validité des paramètres doit être vérifiée à l'intérieur de chaque fonction.

***Justification***: Ceci est possiblement la règle la plus fréquemment violée, et ainsi quelque-part la plus suspecte en tant que règle générale. Dans sa forme la plus stricte, cette règle signifie que même la valeur de retour de appels à *printf* et à *close* doivent être vérifiés. On pourrait arguer, bien sûr, que si la réponse à une erreur est strictement la même qu'en cas de succès, il n'y a que peu d'intérêt à vérifier explicitement une valeur de retour. Ceci est souvent le cas avec les appels à *printf* & *close*. Dans ce genre de cas, il peut être acceptable de cast/typer le retour de la fonction en *(void)* - Indiquant ainsi que le programmeur souhaite ignorer explicitement & non accidentellement une valeur de retour. Dans des cas plus litigieux, un commentaire doit être rpésent pour expliquer pourquoi une valeur de retour n'est pas pertinente. Dans la plupart des cas, cependant, la valeur de retour d'une fonction ne doit pas être ignorée, encore moins si celle-ci doit être propagée dans la chaîne d'appel des fonctions.
Les bibliothèques standard violent notoirement cette règle avec de grave conséquences potentielles. Voyez par exemple, ce qui arrive si vous exécutez accidentellement *strlen(0)*, ou *strcat(s1, s2, -1)* avec la bibliothèque C standard - c'est très vilain. En gardant la règle générale, nous nous assurons que les exceptions doivent être justifiées, avec des outils d'analyse statique qui signaleront les violations. Bien souvent, il sera plus facile de se conformer à cette règle que d'expliquer pourquoi un code non conforme peut être acceptable.

8. ***Règle***: L'utilisation du préprocesseur doit être limitée à l'inclusion des en-têtes & aux définitions de macros simples. Les opérateurs de fusion (##), les listes d'arguments variables (ellipses), & les macros récursives ne sont pas autorisées. Toutes les macros doivent s'étendre en unités syntaxiques complètes. L'utilisation de directives de compilations conditionnelles est aussi souvent douteux, mais ne peut toujours être évitée. Ce qui veut dire qu'il ne devrait que rarement y avoir de justification à plus d'une ou deux directives de compilation conditionnelles même dans de très gros logiciels, au delà de la disposition standard qui consiste à éviter l'inclusion multiple du même fichier d'en-tête. Toute utilisation de ce type doit être signalée par un outil d'analyse statique & justifiée dans le code.

***Justification***: Le préprocesseur C est un outil puissant d'obscurcissement qui peut détruire la clarté du code & perturber nombre d'outils d'analyse textuelle. L'effet des constructions en code préprocesseur sans restrictions peut être extrêmement difficile à déchiffrer, même avec un définition formelle du langage à porté de main. Dans une nouvelle implémentation du préprocesseur C, les développeurs doivent se résoudre à utiliser les plus anciennes implémentations en tant que référence pour l'interprétation du langage de définition complexe du C standard. La justification de 'lavertissement concernant la compilation conditionnelle est tout aussi importante. Notez qu'avec seulement 10 directives de compilation conditionnelle, il pourrait y avoir jusqu'à 2^10 versions possibles du code, chacune d'entre elles devant être testée - provocant une énorme augmentation de l'effort nécessaire en matère de tests.

9. ***Règle***: L'utilisation des pointeurs doit être limitée. Plus précisément, pas plus d'un niveau de déréférencement n'est autorisé. Les opérations de déréférencement des pointeurs ne devraient pas être cachées dans des définitinos de macros ou à l'intérieur de déclarations de type *typedef*. Les pointeurs de fonctions ne sont pas permis.

***Justification***: Les pointeurs sont facilement mal utilisés, même pas des développeur expérimentés. Il peuvent rendre le flux de données dans un programme difficile à suivre ou à analyser, en particuliers par les analyseurs statiques. Les pointeurs de fonctions, de la même façon, peuvent sérieusement limiter les types de vérifications qui peuvent être effectuées par les analyseurs statiques & ne doivent être utilisés qu'accompagnés d'un solide justification, & idéalement de moyens alternatifs sont fournis pour aider les outils d'analyse à déterminer le flux de contrôle & la hiérarchie d'appels des fonctions. En l'occurrence, si des pointeurs de fonction sont utilisés, i peut devenir impossible pour un outil de prouver l'absence de récursion, des garanties alternatives devront être fournies pour combler le vide créé en termes de capacités d'analyse.

10. *** Règle***: Tout le code doit être compilé, à partir du premier jour de développement, avec *tous* les avertissements activés dans le mode le plus pédant du compilateur. Tout le code doit compiler avec ces paramètres sans aucun avertissement. Tout le code doit être vérifié quotidiennement avec au moins un, mais de préférence avec plus d'un, analyseur statique de pointe & passer l'analyse avec zero avertissement.

***justification***: Il existe de nombreux & très efficaces analyseurs statiques de code sur le marché de nos jours, & un bon paquet d'outils gratuits également. Il n'y a simplement aucune excuse pour qu'un développement logiciel n'utilise pas cette technologie immédiatement à disposition. Ceci doit être considéré comme une pratique de routine, même pour du code non-critique. La règle de zéro warnings s'applique même dans les cas où l'analyseur ou le compilateur donne un avertissement erroné : si le compilateur ou l'analyseur est perturbé, le code provoquant la confusion doit être réécrit afin de devnir plus trivialement valide. Beaucoup de développeurs se sont retrouvés piégés en assumant qu'un avertissement était probablement invalide, avant de réaliser bien plus tard que les message était en réalité valide pour des raison moins évidentes. Les analyseurs statiques traînent une mauvaise réputation notamment due à leurs premiers prédecesseurs, comme *lint*, qui produisait dans la plupart des cas des messages invalides, mais ça n'est désormais plus le cas. Les meilleurs analyseurs statiques de nos jours sont rapides & produisent des messages sélectifs & précis. Leur usage doit être non négociable dans n'importe quel projet logiciel sérieux.

Les deux premièeres règles garantissent la création d'une structure de flux de contrôle claire & transparente qui est est plus facile à compiler, tester & analyser. L'absence d'allocation mémoire dynamique, stipulée par la troisième règle, élimine une classe de problèmes liées à l'allocation & la libération de la mémoire, l'utilisation de pointeurs sauvages, etc. Les quelques règles suivantes (4 à 7) sont largement & légitimement acceptées comme des standars pour une bon style de codage. Les avantages d'autres styles de codage qui ont été avancées pour les systèmes critiques de sécurité, e.g., la discipline du "design par contrat" peut partiellement être retrouvée dans les règles 5 à 7.

Cet 10 règlessont utilisées de façon expérimentale à JPL dans l'écriture de logiciels critiques opérationnels, avec des résultats encourageants. Après avoir dépassé une saine réticence initiale à vivre dans des limites aussi strictes, les développeurs trouvent souvent que la conformité d'avec ces règles tend à améliorer les clarté du code, la capacité d'analyse & la sécurité du code. Ces règles amoindrissent le fadreau du développeur & du testeur pour établir des propriétés clés du code (par ex, l'arrêt ou le balisage, l'utilisation sûre de la mémoire & de la pile, etc.) par d'autres moyens. Si ces règles semblent Draconiennes au début, garder à l'esprit qu'elles sont faites pour rendre possible la vérification du code quand, littéralement, votre vie peut dépendre de son exactitude : du code qui est utilisé pour contrôler l'avion dans lequel vous volez, la centrale nucléaire à quelques encablures d'où vous vivez, ou la fusée qui amène les astonautes en orbite. Ces règles sont comme la ceinture de sécurité de votre voiture: au début elle sont peut-être un petit peu inconfortables, mais après un certain temps, leur utilisation devient comme une seconde nature & ne plus les utiliser semble inimaginable.
