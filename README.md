# La puissance de 10 - Des Règles pour Développer du Code Critique Sûr

*Gerard J. Holzmann, traduction par J.Naulet*

*NASA/JPL Laboratory for Reliable Software*

*PAsadena, CA 91109*

La plupart des projets sérieux de développement logiciel utilisent des lignes directrices. Celles-ci ont pour but de définir quelles sont les règles de base pour le logiciel à écrire : comment il doit être structuré & quelles caractéristiques du langage doivent ou ne doivent pas être utilisées. Etonnament, il y a peu de consensus sur ce qu'est un bon standard de codage. Parmi le grand nombre qui ont été écrits, on discerne peu de motifs récurrents, à l'exception du fait que chaque docuement tend à être plus long que le précedent. Le résultat étant que la plupart des documents existants contiennent bien plus d'une centaine de règles, à la justification parfois discutable. Certaines règles, notamment celles qui tentent de définir l'usage des espaces dans les programmes, peuvent avoir été introduites par simple préférence personnelle; d'autres ont pour but d'éviter certains types d'erreurs improbables & très spécifiques, fruit d'efforts précédents au sein d'une même organisation. Sans surprise, les lignes directrices existantes tendent à n'avoir que peu d'effet sur ce que font les developpeurs quand ils écrivent réellement le code. L'aspect le plus élimnatoire de beaucoup de ces lignes directrices est qu'elle autorisent rarement une vérification complète & automatique de la conformité. La vérification par des outils tiers est importante, étant donné qu'il est souvent impossible de faire une revue de code manuelle des milliers de lignes de code présentes dans les plus grosses applications.


Le bénéfice des lignes directrices existantes est par conséquent souvent mineur, même pour les applications critiques. Un ensemble vérifiable de règles de codage bien choisies peut, néanmoins, rendre les éléments logiciels plus analysables en profondeur, pour des propriétés qui vont au delà de la conformité avec ces mêmes règles. Pour être fficace, cependant, cet ensemble de règles doit être concis, et doit être assez clair pour pouvoir être compris & retenu. Les règles devront être suffisamment précises pour pouvoir être vérifiée mécaniquement. Pour mettre une limite haute quant au nombre de règles pour des lignes directrices efficaces, j'arguerais que nous pouvons obtenir un bénéfice significatif en réduisant le nombre à pas plus de 10. Un ensemble aussi réduit, bien sûr, ne peut tout englober, mais il peut nous donner un ancrage pour atteindre des effets mesurables sur la fiabilitié & la vérifiabilite (?) du logiciel. Pour permettre une vérification forte, les règles sont quelque peu strictes - certains diraient même Draconniennes. Le compromis, ceci dit, doit être clair. Quand c'est vraiment important, en particulier lors du développement de code de sécurité critique, il peut être utile d'aller plus loin & de fixer des limites plus strictes que ce qui est simplement souhaitable. En échange, nous devrions être capables de démontrer de façon plus convaincante que le logiciel critique fonctionne comme prévu.

## Dix Règles pour un Code Critique Sûr
Le choix du langage pour un code critique sécurisé est en soi une considération clé, mais nous n'en débattrons pas beaucoup ici. Dans de nombreuses organisations, JPL inclus, le code critique est écrit en C. De par son long historique, il existe un grande bibliothèque d'outils pour ce langage, incluant de puissants analyseurs de code source, des extracteurs de modèles logiques, des outils de mesure, débogueurs, outils de tests, & un vaste choix de compilateurs stables & au point. Pour cette raison, le C est aussi le sujet principal de le plupart des lignes directrices  qui ont été développées. Pour des raisons raisonnablement pragmatiques, donc, nos règles de codage s'appliquent au C & tentent d'optimiser notre capacité à vérifier plus en profondeur la fiabilité des applications critiques écrites en C.

Les règles suivantes peuvent fournir un bénéfice, en particulier si leur faible nombre signifie que les developpeurs vont reéllement les appliquer. Chaque règle s'accompagne d'un rapide résumé qui explique son inclusion.

1. ***Règle***: Réduire le code à des constructions simples de flux de contrôle - N'utilisez pas d'instructions *goto*, *setjmp* ou *longjmp* ni de *récursion* direct ou indirecte.

***Justification***: Un flux de contrôle plus simple se traduit par de plus grandes capacités de vérification & souvent une amélioration de la clarté du code. L'interdiction de la récursion est peut-être le plus grosse surprise ici. Sans récursion, ceci dit, nous avons la garantie d'un arbre d'appels des fonctions acyclique, qui peut être exploîté par des analyseurs de code, et qui peut directement aider à démontrer que toutes les exécutions qui doivent être couvertes le sont. (Notez que cette règle ne requiert pas que toutes les fonctions n'aient qu'un unique point de retour - bien que cela simplifie souvent le flux de contrôle. Il y a suffisamment de cas, en fait, où un retour d'erreur anticipé est la solution la plus simple)

2. ***Règle***: Toutes les boucles doivent avoir une limite haute fixe. Il doit être ridiculement facile pour un outil d'analyse de prouver statiquement qu'une limite d'itérations prédéfinie ne peut être dépassée. Si la limitation ne peut être prouvée de façon statique, la règle est considérée comme violée.

***Justification***: L'absence de récursion & la présence de boucles limitées empêche la jardinage en mémoire. Cette règle, bien sûr, ne s'applique pas aux itérations infinies par essence (ex: dans un scheduler de process). Dans ces cas particuliers, la règle inverse est appliquée: il doit être possible de prouver statiquement que l'itération *ne peut* se terminer.
Une fois d'appliquer cette règle est d'ajouter explicitement une limite haute à toutes les boucles ayant un nombre variable d'itérations (ex: un code qui parcourerait une liste chaînée). Quand la limite haute est dépassée une assertion d'échec est lancée & la fonction contenant l'itération fautive retourne une erreur. (Voir règle 5 sur l'utilisation des assertions).


3. ***Règle***: Ne pas utiliser d'allocation mémoire dynamique après l'initialisation.

***Justification***: Cette règle est courante pour le code critique de sécurité & apparaît dans la plupart des lignes directrices. La raison est simple: les allocateurs mémoire, tels que *malloc* & les ramasse-miettes ont souvent un comprtement non prévisible qui peut impacter la performance de façon significative. Une classe notable d'erreurs de codage émerge d'une mauvaise prise en charge de l'allocation mémoire & des routines de libération: oulbier de libérer la mémoire ou conitnuer à à utiliser la mémoire après qu'elle ait été libérée, tenter d'allouer plus de mémoire qu'il n'y en a de physiquement disponible, dépasser les limites de la mémoire allouée, etc. Forcer toutes les applications à vivre dans une zone mémoire fixe, pré-allouée peut éliminer beaucoup de ces problèmes & rendre la vérification de l'utilisation mémoire plus facile. Notez que la seule façon de demander dynamiquement de la mémoire en l'absence d'allocation mémoire en provenance du tas *(heap)* est d'utiliser la mémoire de la pile. En l'absence de récursion (Règle 1), une limite haute quant à l'utilisation de la pile mémoire peut être déduite statiquement, rendant possible de prouver qu'une application va toujours vivre à l'intérieur de sa zone pré-allouée.

